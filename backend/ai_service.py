import os
import json
from openai import AsyncOpenAI
from dotenv import load_dotenv

load_dotenv()

class AIService:
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            print("Warning: OPENAI_API_KEY is missing in .env")
            self.client = None
        else:
            self.client = AsyncOpenAI(api_key=self.api_key)
        
        # Simple in-memory cache
        self.cache = {}

    async def analyze_safety(self, district: str, year: str, data_summary: dict):
        cache_key = f"{year}_{district}"
        if cache_key in self.cache:
            return self.cache[cache_key]

        if not self.client:
            return "AI ì„œë¹„ìŠ¤ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš” (API KEY ëˆ„ë½)."

        system_prompt = (
            "ë‹¹ì‹ ì€ ë¶€ì‚°ì‹œì˜ ê³µê³µë””ìì¸ ë° ë„ì‹œ ì•ˆì „ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. "
            "ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ êµ¬ì˜ ë„ì‹œ ì•ˆì „, í™˜ê²½, ë²”ì£„ì˜ˆë°© ë””ìì¸(CPTED) ê´€ì ì—ì„œ "
            "ê°„ê²°í•˜ê³  ëª…í™•í•œ ì§„ë‹¨ê³¼ ê°œì„  ë°©ì•ˆì„ í•œêµ­ì–´ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”. "
            "ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„± ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”."
        )

        user_prompt = f"""
        ë¶„ì„ ëŒ€ìƒ: ë¶€ì‚°ê´‘ì—­ì‹œ {district}
        ëŒ€ìƒ ì—°ë„: {year}
        
        ì£¼ìš” ë°ì´í„° ìš”ì•½:
        - ì¢…í•© ì•ˆì „ ì ìˆ˜: {data_summary.get('score', 'N/A')}
        - ë“±ê¸‰: {data_summary.get('grade', 'N/A')}
        - ì£¼ìš” ì§€í‘œ: {json.dumps(data_summary.get('analysis', []), ensure_ascii=False)}
        
        ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‘ ê°€ì§€ í•­ëª©ì— ëŒ€í•´ 300ì ë‚´ì™¸ë¡œ ìš”ì•½ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1. ğŸ” **ì•ˆì „ ì§„ë‹¨**: í˜„ì¬ ì·¨ì•½ì ê³¼ ê¸ì •ì ì¸ ìš”ì†Œ
        2. ğŸ’¡ **ê°œì„  ì œì•ˆ**: ê³µê³µë””ìì¸ì„ í†µí•œ êµ¬ì²´ì ì¸ í•´ê²° ë°©ì•ˆ (ì˜ˆ: ì¡°ëª… ê°œì„ , CCTV ì‚¬ê°ì§€ëŒ€ ë³´ì™„, ì•ˆì‹¬ ê·€ê°“ê¸¸ ì¡°ì„± ë“±)
        """

        try:
            response = await self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=600
            )
            result = response.choices[0].message.content
            self.cache[cache_key] = result
            return result
        except Exception as e:
            # Fallback for demonstration when API Key is invalid or quota exceeded
            return (
                f"âš ï¸ AI ì—°ê²° ë¬¸ì œë¡œ ì¸í•œ ê°€ìƒ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n"
                f"### ğŸ” {year}ë…„ {district} ì•ˆì „ ì§„ë‹¨ ìš”ì•½\n"
                f"- **ì•ˆì „ ë“±ê¸‰**: {data_summary.get('grade')} ({data_summary.get('score')}ì )\n"
                f"- **í˜„í™©**: ì „ë°˜ì ì¸ ì•ˆì „ ì§€ìˆ˜ëŠ” ì–‘í˜¸í•˜ë‚˜, ì•¼ê°„ ë³´í–‰ ì•ˆì „ ì·¨ì•½ êµ¬ê°„ì´ ì¼ë¶€ ì‹ë³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                f"### ğŸ’¡ ê°œì„  ì œì•ˆ\n"
                f"1. **ì¡°ëª… í™˜ê²½ ê°œì„ **: ì–´ë‘ìš´ ê³¨ëª©ê¸¸ì— ìŠ¤ë§ˆíŠ¸ ê°€ë¡œë“± ì¶”ê°€ ì„¤ì¹˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n"
                f"2. **CCTV ë³´ê°•**: ì‚¬ê°ì§€ëŒ€ì— ì§€ëŠ¥í˜• CCTVë¥¼ í™•ì¶©í•˜ì—¬ ë²”ì£„ ì˜ˆë°© íš¨ê³¼ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                f"3. **ì•ˆì‹¬ ê·€ê°“ê¸¸**: ì£¼ë¯¼ë“¤ì˜ ì˜ê²¬ì„ ë°˜ì˜í•œ ì•ˆì‹¬ ê·€ê°“ê¸¸ ë…¸ì„ ì„ ì •ë¹„í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
            )

    async def chat_with_context(self, message: str, history: list, context: dict):
        if not self.client:
            return "AI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        # Construct System Prompt with Context
        district = context.get('district', 'ë¶€ì‚°ì‹œ ì „ì²´')
        year = context.get('year', '2026')
        score = context.get('score', '-')
        grade = context.get('grade', '-')
        
        system_prompt = (
            f"ë‹¹ì‹ ì€ ë¶€ì‚°ì‹œ {district}ì˜ ê³µê³µë””ìì¸ ë° ë„ì‹œ ì•ˆì „ ì „ë¬¸ê°€ 'BDP ë´‡'ì…ë‹ˆë‹¤. "
            f"í˜„ì¬ ì‚¬ìš©ìëŠ” {year}ë…„ë„ ë°ì´í„°ë¥¼ ë³´ê³  ìˆìŠµë‹ˆë‹¤. "
            f"í•´ë‹¹ ì§€ì—­ì˜ ì¢…í•© ì•ˆì „ ì ìˆ˜ëŠ” {score}ì (ë“±ê¸‰: {grade})ì…ë‹ˆë‹¤. "
            "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. "
            "ë‹µë³€ì€ 200ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ í•µì‹¬ë§Œ ì „ë‹¬í•˜ì„¸ìš”."
        )

        # Build messages including history
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add history (limit to last 6 messages to save tokens)
        for msg in history[-6:]:
            messages.append({"role": msg.get("role"), "content": msg.get("content")})
            
        # Add current user message
        messages.append({"role": "user", "content": message})

        try:
            response = await self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=0.7,
                max_tokens=300
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"DEBUG: Chat API Error: {str(e)}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë²„ ì—°ê²°ì´ ì›í™œí•˜ì§€ ì•Šì•„ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

ai_service = AIService()
